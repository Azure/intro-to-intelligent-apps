{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Langchain with Azure Cognitive Search\n",
    "\n",
    "In this lab, we will do a deeper dive around the Azure Cognitive Search (ACS) vector store and different ways to interact with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Cognitive Search Vector Store in Azure\n",
    "\n",
    "First, we need to create an Azure Cognitive Search (ACS) vector store in Azure. We'll use the Azure CLI to do this.\n",
    "\n",
    "**Note:** Update **INITIALS** to make the name unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RG=\"azure-cognitive-search-rg\"\n",
    "LOC=\"westeurope\"\n",
    "NAME=\"acs-vectorstore-<INITIALS>\"\n",
    "!az group create --name $RG --location $LOC\n",
    "!az search service create -g $RG -n $NAME -l $LOC --sku Basic --partition-count 1 --replica-count 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to find and update the following values in the **.env** file with the Azure Cognitive Search **endpoint**, **admin key**, and **index name** values. Use the Azure Portal or CLI.\n",
    "\n",
    "AZURE_COGNITIVE_SEARCH_SERVICE_NAME = \"<YOUR AZURE COGNITIVE SEARCH SERVICE NAME - e.g. cognitive-search-service>\"\n",
    "AZURE_COGNITIVE_SEARCH_ENDPOINT_NAME = \"<YOUR AZURE COGNITIVE SEARCH ENDPOINT NAME - e.g. https://cognitive-search-service.search.windows.net\"\n",
    "AZURE_COGNITIVE_SEARCH_INDEX_NAME = \"<YOUR AZURE COGNITIVE SEARCH INDEX NAME - e.g. cognitive-search-index>\"\n",
    "AZURE_COGNITIVE_SEARCH_API_KEY = \"<YOUR AZURE COGNITIVE SEARCH ADMIN API KEY - e.g. cognitive-search-admin-api-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure OpenAI and Langchain\n",
    "\n",
    "We'll start as usual by defining our Azure OpenAI service API key and endpoint details, specifying the model deployment we want to use and then we'll initiate a connection to the Azure OpenAI service.\n",
    "\n",
    "**NOTE**: As with previous labs, we'll use the values from the `.env` file in the root of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found OpenAPI Base Endpoint: \" + os.getenv(\"OPENAI_API_BASE\"))\n",
    "else: \n",
    "    print(\"No file .env found\")\n",
    "\n",
    "openai_api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai_api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "embedding_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "acs_service_name = os.getenv(\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\")\n",
    "acs_endpoint_name = os.getenv(\"AZURE_COGNITIVE_SEARCH_ENDPOINT_NAME\")\n",
    "acs_index_name = os.getenv(\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\")\n",
    "acs_api_key = os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data from the movies.csv file using a Langchain document loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='./movies.csv', source_column='original_title', encoding='utf-8', csv_args={'delimiter':',', 'fieldnames': ['id', 'original_language', 'original_title', 'popularity', 'release_date', 'vote_average', 'vote_count', 'genre', 'overview', 'revenue', 'runtime', 'tagline']})\n",
    "data = loader.load()\n",
    "data = data[1:21] # reduce dataset if you want\n",
    "print('Loaded %s movies' % len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create an Azure OpenAI embedding and completion deployments in order to create the vector representation of the movies in the loaded CSV file and then be able to ask questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "# Create an Embeddings Instance of Azure OpenAI\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=embedding_name,\n",
    "    chunk_size=1\n",
    ") \n",
    "\n",
    "# Create a Completion Instance of Azure OpenAI\n",
    "llm = AzureOpenAI(\n",
    "    openai_api_type = openai_api_type,\n",
    "    openai_api_version = openai_api_version,\n",
    "    openai_api_base = openai_api_base,\n",
    "    openai_api_key = openai_api_key,\n",
    "    deployment_name = deployment_name,\n",
    "    model_name=\"gpt-35-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Movies into Azure Cognitive Search (ACS)\n",
    "\n",
    "Next, we'll configure Langchain to use ACS as vector store, embedd the loaded documents and store the embeddings in the vector store. Depending on the number of movies loaded and rate limiting, this might take a while.\n",
    "\n",
    "Here is a great link highlighting how Langchain and Azure Cognitive Search work together: https://python.langchain.com/docs/integrations/vectorstores/azuresearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=acs_endpoint_name,\n",
    "    azure_search_key=acs_api_key,\n",
    "    index_name=acs_index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store Searching using Azure Cognitive Search (ACS)\n",
    "\n",
    "Now that we have the movies loaded into ACS, let's do some searches using the ACS API via the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What are the best 80s movies I should look?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\"\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What are the best 80s movies I should look?\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\"\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store Searching using Langchain Retriever\n",
    "\n",
    "In this part we will use Langchain to search Azure Cognitive Search, retrieve the results, then interact with the LLM in Azure OpenAI. This is different than the previous section where we were using Azure Cognitive Serach's search API directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now combine the Search with Azure OpenAI\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "\n",
    "retriever = AzureCognitiveSearchRetriever(\n",
    "    service_name=acs_service_name,\n",
    "    api_key=acs_api_key,\n",
    "    index_name=acs_index_name,\n",
    "    content_key=\"content\",\n",
    "    top_k=2\n",
    ")\n",
    "\n",
    "retriever.get_relevant_documents(\"What is the best movie of all time?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do NOT include source documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the retriever in combination with the LLM in Azure OpenAI.\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Do NOT include the source documents in the response.\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"question\",\n",
    "    return_source_documents=False\n",
    ")\n",
    "query = \"What is the best movie of all time?\"\n",
    "response = chain({\"question\": query})\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include source documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the retriever in combination with the LLM in Azure OpenAI.\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Include the source documents in the response.\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"question\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "query = \"What is the best movie of all time?\"\n",
    "response = chain({\"question\": query})\n",
    "print(response['result'])\n",
    "print(response['source_documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [Deploy AI](../../04-deploy-ai/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
