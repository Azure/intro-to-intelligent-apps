{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - AI Orchestration with Azure AI Search\n",
    "**(Langchain / Python version)**\n",
    "\n",
    "In this lab, we will do a deeper dive into using Azure AI Search as a vector store, the different search methods it supports and how you can use it as part of the Retrieval Augmented Generation (RAG) pattern for working with large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure AI Search Vector Store in Azure\n",
    "\n",
    "First, we will create an Azure AI Search service in Azure. The following are command line instructions and require the Azure CLI to be installed.\n",
    "\n",
    "**NOTE:** Before running the commands, replace the **`<INITIALS>`** with your own initials or some random characters, as we need to provide a unique name for the Azure AI Search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_GROUP=\"azure-ai-search-rg\"\n",
    "LOCATION=\"westeurope\"\n",
    "NAME=\"ai-vectorstore-<INITIALS>\"\n",
    "!az group create --name $RESOURCE_GROUP --location $LOCATION\n",
    "!az search service create -g $RESOURCE_GROUP -n $NAME -l $LOCATION --sku Basic --partition-count 1 --replica-count 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to find and update the following values in the `.env` file with the Azure AI Search **name**, **endpoint** and **admin key** values, which you can get from the Azure portal. You also need to provide an **index name** value. The index will be created during this lab, so you can use any name you like.\n",
    "\n",
    "```\n",
    "AZURE_AI_SEARCH_SERVICE_NAME = \"<YOUR AZURE AI SEARCH SERVICE NAME - e.g. ai-vectorstore-xyz>\"\n",
    "AZURE_AI_SEARCH_ENDPOINT = \"<YOUR AZURE AI SEARCH ENDPOINT URL - e.g. https://ai-vectorstore-xyz.search.windows.net\"\n",
    "AZURE_AI_SEARCH_INDEX_NAME = \"<YOUR AZURE AI SEARCH INDEX NAME - e.g. ai-search-index>\"\n",
    "AZURE_AI_SEARCH_API_KEY = \"<YOUR AZURE AI SEARCH ADMIN API KEY - e.g. get this value from the Azure portal>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variable values\n",
    "As with previous labs, we'll use the values from the `.env` file in the root of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"This lab exercise will use the following values:\")\n",
    "    print(\"Azure OpenAI Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "    print(\"Azure AI Search: \" + os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\"))\n",
    "else: \n",
    "    print(\"No file .env found\")\n",
    "\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "azure_openai_completion_deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_ai_search_name = os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\")\n",
    "azure_ai_search_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "azure_ai_search_index_name = os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\")\n",
    "azure_ai_search_api_key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data from the movies.csv file and then extract a subset to load into the Azure AI Search index. We do this to help avoid the Azure OpenAI embedding limits and long loading times when inserting data into the index. We use a Langchain document loader to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='./movies.csv', source_column='original_title', encoding='utf-8', csv_args={'delimiter':',', 'fieldnames': ['id', 'original_language', 'original_title', 'popularity', 'release_date', 'vote_average', 'vote_count', 'genre', 'overview', 'revenue', 'runtime', 'tagline']})\n",
    "data = loader.load()\n",
    "\n",
    "# Rather than load all 500 movies into Azure AI search, we will use a\n",
    "# smaller subset of movie data to make things quicker. The more movies you load,\n",
    "# the more time it will take for embeddings to be generated.\n",
    "\n",
    "data = data[1:51]\n",
    "print('Loaded %s movies.' % len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this lab, we will need to work with embeddings. We use embeddings to create a vector representation of a piece of text. We will need to create embeddings for the documents we want to store in our Azure AI Search index and also for the queries we want to use to search the index. We will create an Azure OpenAI client to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version = os.getenv(\"OPENAI_EMBEDDING_API_VERSION\"),\n",
    "    model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure AI Search index and load movie data\n",
    "\n",
    "Next, we'll step through the process of configuring an Azure AI Search index to store our movie data and then loading the data into the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SemanticField,\n",
    "    SemanticConfiguration,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex\n",
    ")\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When configuring an Azure AI Search index, we need to specify the fields we want to store in the index and the data types for each field. These match the fields in the movie data, containing values such as the movie title, genre, year of release and so on.\n",
    "\n",
    "To use Azure AI Search as a vector store, we will also need to define a field to hold the vector representaion of the movie data. We indicate to Azure AI Search that this field will contain vector data by providing details of the vector dimensions and a profile. We'll also define the vector search configuration and profile with default values.\n",
    "\n",
    "**NOTE:** It is possible just to use Azure AI Search as a vector store only, in which case we probably wouldn't need to define all of the index fields below. However, in this lab, we're also going to demonstrate Hybrid Search, a feature which makes use of both traditional keyword based search in combination with vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"overview\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"genre\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"tagline\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"release_date\", type=SearchFieldDataType.DateTimeOffset, sortable=True),\n",
    "    SearchableField(name=\"popularity\", type=SearchFieldDataType.Double, sortable=True),\n",
    "    SearchableField(name=\"vote_average\", type=SearchFieldDataType.Double, sortable=True),\n",
    "    SearchableField(name=\"vote_count\", type=SearchFieldDataType.Int32, sortable=True),\n",
    "    SearchableField(name=\"runtime\", type=SearchFieldDataType.Int32, sortable=True),\n",
    "    SearchableField(name=\"revenue\", type=SearchFieldDataType.Int64, sortable=True),\n",
    "    SearchableField(name=\"original_language\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"movies-vector-profile\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    profiles=[VectorSearchProfile(name=\"movies-vector-profile\", algorithm_configuration_name=\"movies-vector-config\")],\n",
    "    algorithms=[HnswAlgorithmConfiguration(name=\"movies-vector-config\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using Semantic Ranking, a feature of Azure AI Search that improves search results by using language understanding to rerank the search results. We provide a Semantic Search Configuration to help the ranking model understand the movie data, by telling it which fields contain the movie title, which fields contain keywords and which fields contain general free text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"movies-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"genre\")],\n",
    "        content_fields=[SemanticField(field_name=\"title\"),\n",
    "                        SemanticField(field_name=\"overview\"),\n",
    "                        SemanticField(field_name=\"tagline\"),\n",
    "                        SemanticField(field_name=\"genre\"),\n",
    "                        SemanticField(field_name=\"release_date\"),\n",
    "                        SemanticField(field_name=\"popularity\"),\n",
    "                        SemanticField(field_name=\"vote_average\"),\n",
    "                        SemanticField(field_name=\"vote_count\"),\n",
    "                        SemanticField(field_name=\"runtime\"),\n",
    "                        SemanticField(field_name=\"revenue\"),\n",
    "                        SemanticField(field_name=\"original_language\")],\n",
    "    )\n",
    ")\n",
    "\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll go ahead and create the index by creating an instance of the `SearchIndex` class and adding the keyword and vectors fields and the semantic search profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search index with the desired vector search and semantic configurations\n",
    "index = SearchIndex(\n",
    "    name=azure_ai_search_index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    azure_ai_search_endpoint,\n",
    "    AzureKeyCredential(azure_ai_search_api_key)\n",
    ")\n",
    "\n",
    "result = index_client.create_or_update_index(index)\n",
    "\n",
    "print(f'Index {result.name} created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is now ready, so next we need to prepare the movie data to load into the index.\n",
    "\n",
    "**NOTE**: During this phase, we send the data for each movie to an Azure OpenAI embeddings model to create the vector data. This may take some time due to rate limiting in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all of the movies and create a new item for each one.\n",
    "\n",
    "items = []\n",
    "for movie in data:\n",
    "    content = movie.page_content\n",
    "    fields = movie.page_content.split('\\n')\n",
    "    movieId = (fields[0].split(': ')[1])[:-2]\n",
    "    movieTitle = (fields[2].split(': ')[1])\n",
    "    movieOverview = (fields[8].split(': ')[1])\n",
    "    movieGenre = (fields[7].split(': ')[1])[1:-1]\n",
    "    movieTagline = (fields[11].split(': ')[1])\n",
    "    movieReleaseDate = (fields[4].split(': ')[1])\n",
    "    moviePopularity = (fields[3].split(': ')[1])\n",
    "    movieVoteAverage = (fields[5].split(': ')[1])\n",
    "    movieVoteCount = (fields[6].split(': ')[1])\n",
    "    movieRuntime = (fields[10].split(': ')[1])\n",
    "    movieRevenue = (fields[9].split(': ')[1])\n",
    "    movieOriginalLanguage = (fields[1].split(': ')[1])\n",
    "\n",
    "    items.append(dict([\n",
    "        (\"id\", movieId), \n",
    "        (\"title\", movieTitle),\n",
    "        (\"overview\", movieOverview),\n",
    "        (\"genre\", movieGenre),\n",
    "        (\"tagline\", movieTagline),\n",
    "        (\"release_date\", movieReleaseDate),\n",
    "        (\"popularity\", moviePopularity),\n",
    "        (\"vote_average\", movieVoteAverage),\n",
    "        (\"vote_count\", movieVoteCount),\n",
    "        (\"runtime\", movieRuntime),\n",
    "        (\"revenue\", movieRevenue),\n",
    "        (\"original_language\", movieOriginalLanguage),\n",
    "        (\"vector\", azure_openai_embeddings.embed_query(content))\n",
    "    ]))\n",
    "\n",
    "    print(f\"Movie {movieTitle} added.\")\n",
    "\n",
    "print(f\"New items structure with embeddings created for {len(items)} movies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write out the contents of one of the documents to see what it looks like. You can see that it contains the movie data at the top and then a long array containing the vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the movie data stored in the correct format, so let's load it into the Azure AI Search index we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(\n",
    "    azure_ai_search_endpoint,\n",
    "    azure_ai_search_index_name,\n",
    "    AzureKeyCredential(azure_ai_search_api_key)\n",
    ")\n",
    "\n",
    "result = search_client.upload_documents(items)\n",
    "\n",
    "print(f\"Successfully loaded {len(data)} movies into Azure AI Search index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector store searching using Azure AI Search\n",
    "\n",
    "We've loaded the movies into Azure AI Search, so now let's experiment with some of the different types of searches you can perform.\n",
    "\n",
    "First we'll just perform a simple keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"hero\"\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    query_type=\"simple\",\n",
    "    include_total_count=True,\n",
    "    top=5\n",
    "))\n",
    "\n",
    "for result in results:\n",
    "    print(\"Movie: {}\".format(result[\"title\"]))\n",
    "    print(\"Genre: {}\".format(result[\"genre\"]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get some results, but they're not necessarily movies about heroes. It could be that there is some text in the index for these results that relates to the word \"hero\". For example, the description might mention \"heroic deeds\" or something similar.\n",
    "\n",
    "Let's now try the same again, but this time we'll ask a question instead of just searching for a keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the best movies about superheroes?\"\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    query_type=\"simple\",\n",
    "    include_total_count=True,\n",
    "    top=5\n",
    "))\n",
    "\n",
    "for result in results:\n",
    "    print(\"Movie: {}\".format(result[\"title\"]))\n",
    "    print(\"Genre: {}\".format(result[\"genre\"]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, you will likely get mixed results. Some of the movies returned could be about heroes, but others may not be. This is because the search is still based on keywords.\n",
    "\n",
    "Next, let's try a vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the best movies about superheroes?\"\n",
    "\n",
    "vector = VectorizedQuery(vector=azure_openai_embeddings.embed_query(query), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "# Note the `None` value for the `search_text` parameter. This is because we're not sending the query text to Azure AI Search. We're sending the embedded version of the query text instead via the `vector_queries` parameter.\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=None,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"movies-semantic-config\",\n",
    "    vector_queries=[vector],\n",
    "    select=[\"title\", \"genre\"],\n",
    "    top=5\n",
    "))\n",
    "\n",
    "for result in results:\n",
    "    print(\"Movie: {}\".format(result[\"title\"]))\n",
    "    print(\"Genre: {}\".format(result[\"genre\"]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's likely that the raw vector search didn't return exactly what you were expecting. You were probably expecting a list of superhero movies, but now we're getting a list of movies that are **similar** to the vector we provided. Some of these may be hero movies, but others may not be. The vector search is returning the nearest neighbours to the vector we provided, so it's possible that at least one of the results is a superhero movie, and the others are similar to that movie in some way.\n",
    "\n",
    "So, both the keyword search and the vector search have their limitations. The keyword search is limited to the keywords in the index, so it's possible that we might miss some movies that are about heroes. The vector search is limited to returning the nearest neighbours to the vector we provide, so it's possible that we might get some movies that are not about heroes.\n",
    "\n",
    "## Hybrid search using Azure AI Search\n",
    "\n",
    "To overcome the limitations of both keyword search and vector search, we can use a combination of both. This is known as Hybrid Search. Let's run the same query again, but this time we'll use Hybrid Search.\n",
    "\n",
    "The only significant difference is that this time we will submit both the original query text and the embedding vector to Azure AI Search. Azure AI Search will then use both the query text and the vector to perform the search and combine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the best movies about superheroes?\"\n",
    "\n",
    "vector = VectorizedQuery(vector=azure_openai_embeddings.embed_query(query), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "# Note the `None` value for the `search_text` parameter. This is because we're not sending the query text to Azure AI Search. We're sending the embedded version of the query text instead via the `vector_queries` parameter.\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"movies-semantic-config\",\n",
    "    vector_queries=[vector],\n",
    "    select=[\"title\", \"genre\"],\n",
    "    top=5\n",
    "))\n",
    "\n",
    "for result in results:\n",
    "    print(\"Movie: {}\".format(result[\"title\"]))\n",
    "    print(\"Genre: {}\".format(result[\"genre\"]))\n",
    "    print(\"Score: {}\".format(result[\"@search.score\"]))\n",
    "    print(\"Reranked score: {}\".format(result[\"@search.reranker_score\"]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you'll now see a much better set of results. Performing a hybrid search has allowed us to combine the benefits of both keyword search and vector search. But also, Azure AI Search performs a further step when using hybrid search. It makes use of a Semantic Ranker to further improve the search results. The Semantic Ranker uses a language understanding model to understand the query text and the documents in the index and then uses this information to rerank the search results. So, after performing the keyword and vector search, Azure AI Search will then use the Semantic Ranker to re-order the search results based on the context of the original query.\n",
    "\n",
    "In the results above, you can see a `Reranked Score`. This is the score that has been calculated by the Semantic Ranker. The `Score` is the score calculated by the keyword and vector search. You'll note that the results are returned in the order determined by the reranked score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it All Together with Retrieval Augmented Generation (RAG) + Langchain (LC)\n",
    "\n",
    "Now that we have our Vector Store setup and data loaded, we are now ready to implement the RAG pattern using AI Orchestration. At a high-level, the following steps are required:\n",
    "1. Ask the question\n",
    "2. Create Prompt Template with inputs\n",
    "3. Get Embedding representation of inputted question\n",
    "4. Use embedded version of the question to search Azure AI Search (ie. The Vector Store)\n",
    "5. Inject the results of the search into the Prompt Template & Execute the Prompt to get the completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement RAG using Langchain (LC)\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "azure_openai = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "# Ask the question\n",
    "query = \"What are the best movies about superheroes?\"\n",
    "\n",
    "# Create a prompt template with variables, note the curly braces\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_question\",\"search_results\"],\n",
    "    template=\"\"\"\n",
    "    Question: {original_question}\n",
    "\n",
    "    Do not use any other data.\n",
    "    Only use the movie data below when responding.\n",
    "    Provide detailed information about the synopsis of the movie.\n",
    "    {search_results}\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# Search Vector Store\n",
    "search_client = SearchClient(\n",
    "    azure_ai_search_endpoint,\n",
    "    azure_ai_search_index_name,\n",
    "    AzureKeyCredential(azure_ai_search_api_key)\n",
    ")\n",
    "\n",
    "vector = VectorizedQuery(vector=azure_openai_embeddings.embed_query(query), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"movies-semantic-config\",\n",
    "    include_total_count=True,\n",
    "    vector_queries=[vector],\n",
    "    select=[\"title\",\"genre\",\"overview\",\"tagline\",\"release_date\",\"popularity\",\"vote_average\",\"vote_count\",\"runtime\",\"revenue\",\"original_language\"],\n",
    "    top=5\n",
    "))\n",
    "\n",
    "# Build the Prompt and Execute against the Azure OpenAI to get the completion\n",
    "chain = LLMChain(llm=azure_openai, prompt=prompt, verbose=False)\n",
    "response = chain.invoke({\"original_question\": query, \"search_results\": results})\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "📣 [Deploy AI](../../04-deploy-ai/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
