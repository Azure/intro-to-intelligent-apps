{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Semantic Kernel\n",
    "\n",
    "In this lab, we will introduce **Semantic Kernel**. Like **Langchain**, it provides a framework for working with AI models and supports applications written in Python. Semantic Kernel also adds support for .NET and Java applications.\n",
    "\n",
    "As with the other labs, we'll start by reading in values from the `.env` file.\n",
    "\n",
    "___\n",
    "**NOTE**: This lab uses **.NET** so be sure to select .NET and not Python when starting to use this notebook.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: dotenv.net, 3.1.2\"\n",
    "\n",
    "using dotenv.net;\n",
    "\n",
    "// Read values from .env file\n",
    "var envVars = DotEnv.Fluent()\n",
    "    .WithoutExceptions()\n",
    "    .WithEnvFiles(\"../../../.env\")\n",
    "    .WithTrimValues()\n",
    "    .WithDefaultEncoding()\n",
    "    .WithOverwriteExistingVars()\n",
    "    .WithoutProbeForEnv()\n",
    "    .Read();\n",
    "\n",
    "// Load values into variables and strip quotes\n",
    "var model = envVars[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"].Replace(\"\\\"\", \"\");\n",
    "var azureEndpoint = envVars[\"AZURE_OPENAI_ENDPOINT\"].Replace(\"\\\"\", \"\");\n",
    "var apiKey = envVars[\"AZURE_OPENAI_API_KEY\"].Replace(\"\\\"\", \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start working with Semantic Kernel, we'll need to load its nuget package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.10.0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Kernel works by creating an instance of the Kernel and then adding in various plugins to perform different functions. Those plugins or functions can then be called individually or chained together to perform more complex tasks.\n",
    "\n",
    "We use the standard .NET `builder` pattern to initialise the kernel. Notice that we pass in the details of the completion model that we're going to use, the Azure OpenAI API endpoint URL and the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "var builder = Kernel.CreateBuilder();\n",
    "builder.Services.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);\n",
    "var kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using Semantic Kernel\n",
    "\n",
    "Now that we've established a connection to the Azure OpenAI API, we can go ahead and send a prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "Console.WriteLine(await kernel.InvokePromptAsync(\"What things could I make with a Raspberry Pi?\"));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take that simple prompt forward and create a function with a prompt template to perform a simple request to Azure OpenAI. The template allows us to define a prompt and add placeholders for values that we will provide later. These values could come from user input, or another function, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var whatCanIMakeFunction = kernel.CreateFunctionFromPrompt(\n",
    "    new PromptTemplateConfig()\n",
    "    {\n",
    "        Template = @\"What interesting things can I make with a {{$item}}?\",\n",
    "        InputVariables = [\n",
    "            new() { Name = \"item\", Description = \"An item to make something with.\", IsRequired=true }\n",
    "        ]\n",
    "    });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`{{$item}}` represents the value we will provide later and will be replaced when we make the call to Azure OpenAI.\n",
    "\n",
    "Next, we'll define a value for `item` and then call the function, passing in the `item` as we do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string item = \"raspberry pi\";\n",
    "\n",
    "var response = await kernel.InvokeAsync(whatCanIMakeFunction, new () { { \"item\", item }});\n",
    "\n",
    "Console.WriteLine(response);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of ideas for things we could make with a Raspberry Pi. \n",
    "\n",
    "We could then use Semantic Kernel to take that list of ideas and summarize it. First, we'll create a new prompt that will generate a summary of some text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var thingsToMakeSummary = kernel.CreateFunctionFromPrompt(\n",
    "    new PromptTemplateConfig()\n",
    "    {\n",
    "        Template = @\"Summarize the following text: {{$thingsToMake}}?\",\n",
    "        InputVariables = [\n",
    "            new() { Name = \"thingsToMake\", Description = \"A list of things you could make.\", IsRequired=true }\n",
    "        ]\n",
    "    });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can call the kernel again, this time passing in the list of ideas, the `response` from the previous call, as the value for `thingsToMake`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var summary = await kernel.InvokeAsync(thingsToMakeSummary, new () { { \"thingsToMake\", response }});\n",
    "\n",
    "Console.WriteLine(summary);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Semantic Kernel is another example of an AI orchestrator. Like other orchestrators, it can be used to simplify the process of creating complex AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [AI Orchestration](../../03-orchestration/README.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
