{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Using the OpenAI Library\n",
    "\n",
    "In the [first](../01-AzureOpenAIAPI/azureopenaiapi.ipynb) lab, we walked through calling the Azure OpenAI API directly to submit a prompt for completion. An easier way to work with an API is to use a *Library*. A Library is a collection of packages and modules that allow reusable code to be shared with the community.\n",
    "\n",
    "In this lab, we'll use the OpenAI Python library to perform the same operations as we did in the first lab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `import` statement to let our application know that we're going to be using the OpenAI library in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll start to bring in the values from our `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a new `AzureOpenAI` object and pass in the API key and version and the endpoint URL to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the OpenAI library\n",
    "\n",
    "Now that we have defined an Azure OpenAI instance, let's try a Chat Completion. We'll call the `chat.completions.create()` method. Note that for the `model` value, we actually pass in the id of our Azure OpenAI `deployment`. We'll also pass the `prompt` we want to use as the `content` of the `messages` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response above should be similar JSON data to what we got when we called the API directly in the previous exercise, containing details of the model we called, the response that was generated and the token usage.\n",
    "\n",
    "We can use the structured response returned by the API to just extract the generated response text on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The OpenAI library provides a more concise way to work with the OpenAI API. Once we've set up the initial parameters, we don't need to send them each time as we need to do with a direct API call. It's also easier to add information such as prompts to the call, as we can pass those values in as part of the call to the OpenAI library methods instead of having to pass in JSON objects as part of the request body.\n",
    "\n",
    "You can find more details about the completions API in the reference documentation:\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab we'll begin looking at AI orchestrators. Whereas the OpenAI library simplfies working with the OpenAI API, orchestrators take things to the next level!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [Langchain](../03-Langchain/langchain.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
