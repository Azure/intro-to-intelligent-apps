{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Connecting to the Azure OpenAI API to explore prompt engineering\n",
    "\n",
    "In this lab, we will connect to our Azure OpenAI API for practicing prompt engineering. For each exercise, you'll get some input text and then an expected completion. Your task is to write the prompt to achieve the expected completion.\n",
    "\n",
    "But first we will run a few test API calls to make sure everything works.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to retrieve values from the `.env` file which we will use to make calls to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OpenAI API Base Endpoint: https://aoai-jkordick.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found OpenAI API Base Endpoint: \" + os.getenv(\"OPENAI_API_BASE\"))\n",
    "else: \n",
    "    print(\"OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# This version of the API is needed to properly retrieve the list of model deployments.\n",
    "API_VERSION = \"2023-03-15-preview\"\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set the endpoint that we're going to call. This endpoint will return a list of available model deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aoai-jkordick.openai.azure.com//openai/deployments?api-version=2023-03-15-preview\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments?api-version=\" + API_VERSION\n",
    "\n",
    "print (url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you will see the full URL that we are going to be calling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of available Model Deployments\n",
    "\n",
    "Now let's call that Azure OpenAI endpoint and see what it returns. We pass the API key in the HTTP header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"gpt-35-turbo-16k\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"gpt-35-turbo-16k-240k\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1695647543,\n",
      "      \"updated_at\": 1695647543,\n",
      "      \"object\": \"deployment\"\n",
      "    },\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"text-embedding-ada-002\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"text-embedding-ada-002-240k\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1695647595,\n",
      "      \"updated_at\": 1695647595,\n",
      "      \"object\": \"deployment\"\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, there should now be a JSON formatted list of model deployments. The output will contain one or more sections similar to the following\n",
    "\n",
    "```\n",
    "    {\n",
    "      \"scale_settings\": {\n",
    "        \"scale_type\": \"standard\"\n",
    "      },\n",
    "      \"model\": \"gpt-35-turbo\",\n",
    "      \"owner\": \"organization-owner\",\n",
    "      \"id\": \"gpt35turbo\",\n",
    "      \"status\": \"succeeded\",\n",
    "      \"created_at\": 1684150536,\n",
    "      \"updated_at\": 1684150536,\n",
    "      \"object\": \"deployment\"\n",
    "    }\n",
    "```\n",
    "\n",
    "In the output, you'll see the **Model Name** as the `model` value and the **Deployment Name** as the `id` value. We'll be using an `id` value for the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send our first prompt to Azure OpenAI using the API\n",
    "\n",
    "Next, let's call the Azure OpenAI API with a prompt. To do this, we'll need the `id` of our completion model deployment.\n",
    "\n",
    "We've already setup this value in the `.env` file, but you should see a matching value in the list that was output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab API Version in the .env file.\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll construct a URL to call. This time, we'll also be creating a payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aoai-jkordick.openai.azure.com//openai/deployments/gpt-35-turbo-16k-240k/chat/completions?api-version=2023-05-15\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=\" + API_VERSION\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you will see the full URL that we are going to call. This URL will use the specified deployment to call the **chat completions** API.\n",
    "\n",
    "Next, we will call the Azure OpenAI API using the URL above. Just like last time, we pass the API key in the HTTP header. We also send a JSON formatted body as part of the request which contains the *prompt* that we want to use to get a response from the OpenAI model. In this case, our prompt is \"Once upon a time\", which should cause the model to complete the prompt by generating a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-82gSwUD94gNKZcnh301MByf19Qf5K\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695650586,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"in a small village, there lived a young girl named Lily. She had long, flowing red hair and bright blue eyes. Lily was known for her kindness and helpful nature.\\n\\nOne day, as Lily was walking through the village, she noticed an elderly woman struggling to carry a heavy bag of groceries. Without hesitation, Lily hurried over and offered her assistance. The woman gratefully accepted, and they walked together to the woman's house.\\n\\nInside, the woman introduced herself as Mrs. Jones. She lived alone and found it difficult to manage certain tasks due to her age. Lily spent the afternoon helping Mrs. Jones with various chores around the house, from cleaning to organizing.\\n\\nAs the days went by, Lily and Mrs. Jones formed a strong bond. Lily visited Mrs. Jones every day after school, bringing her fresh flowers or homemade treats. They would spend hours talking, playing games, and even working on puzzles together.\\n\\nOne day, while helping Mrs. Jones in her attic, Lily stumbled upon an old, dusty book hidden beneath a pile of boxes. Curiosity piqued, Lily carefully dusted off the book and opened it. To her surprise, the book was filled with magical stories and captivating illustrations.\\n\\nExcitedly, Lily showed the book to Mrs. Jones, who explained that it was a book of fairy tales and legends passed down through generations in her family. Mrs. Jones told Lily that the book had special powers and could transport its readers to the worlds within its pages.\\n\\nCuriosity overwhelmed Lily, and she asked Mrs. Jones if she could venture into one of the stories. Mrs. Jones agreed, knowing that Lily's pure heart and brave spirit would guide her safely through any adventure.\\n\\nLily chose a story about a mystical forest filled with talking animals and hidden treasures. As she found herself inside the story, Lily was amazed by the beauty and magic surrounding her. She met talking squirrels, wise owls, and even stumbled upon a hidden treasure chest.\\n\\nAfter what felt like hours, Lily returned from the story, filled with wonder and excitement. She shared her incredible journey with Mrs. Jones, who smiled knowingly. From that day on, Lily and Mrs. Jones would choose a new story every week and embark on magical adventures together.\\n\\nWord of Lily's incredible adventures with Mrs. Jones spread throughout the village. People started calling Mrs. Jones the \\\"Storyteller\\\" and admired their unique bond. The village soon realized the power of storytelling, and people began coming to Mrs. Jones with their own stories and dreams.\\n\\nLily and Mrs. Jones continued their adventures, bringing joy and inspiration to their village. Lily grew into a wise and compassionate young woman, always ready to lend a helping hand and share the magic of storytelling.\\n\\nAnd so, their remarkable journey continued, with Lily and Mrs. Jones reminding everyone that the power of imagination and the bonds of friendship can create extraordinary adventures that last a lifetime.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 587,\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"total_tokens\": 598\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "content = \"Once upon a time\"\n",
    "\n",
    "r = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": content}]})\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the result of the API call will be JSON data similar to the below example.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-7wVxE2LNxaY6ZoxcWAmhiyrqaLZgf\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1694180212,\n",
    "  \"model\": \"gpt-35-turbo\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \", there was a magical kingdom called Tildor ... )))\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 366,\n",
    "    \"prompt_tokens\": 13,\n",
    "    \"total_tokens\": 379\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here's some more information about some of the data contained in that response.\n",
    "\n",
    "Key | Description\n",
    "--- | ---\n",
    "`model` | The model that was used to generate the response to the prompt\n",
    "`content` | This is the response that was generated by the OpenAI model. Note that the response example above was edited to remove most of the output to make it easier to read\n",
    "`finish_reason` | This is the reason that the model stopped generating the response. In this case, `stop` indicates the model determined it had fully completed the response without hitting any limits\n",
    "`completion_tokens` | The number of tokens that were used in generating the response\n",
    "`prompt_tokens` | The number of tokens that were consumed by the prompt\n",
    "`total_tokens` | The total number of tokens that were consumed by the request (`prompt_tokens` + `completion_tokens`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to our first exercise!\n",
    "\n",
    "You can use the following code snippet where you can set your own prompt into the content variable.\n",
    "\n",
    "We adjusted the `print` command to make the handling a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
      "Sed sed justo libero.\n",
      "Vivamus viverra mi sit amet purus rutrum, sit amet tincidunt nibh porttitor.\n",
      "Phasellus aliquam condimentum nibh, ac dignissim ante placerat ac.\n",
      "Donec hendrerit, justo at vestibulum aliquam, lectus nunc bibendum augue, at fringilla neque diam vel ligula.\n",
      "Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Fusce dictum ex vel libero sodales faucibus.\n",
      "Curabitur erat sapien, vulputate a tristique a, eleifend vel ligula.\n",
      "Interdum et malesuada fames ac ante ipsum primis in faucibus.\n"
     ]
    }
   ],
   "source": [
    "content = 'Hello World'\n",
    "\n",
    "multiline_content = 'This is a multiline string. \\\n",
    "It can span multiple lines and contain line breaks.'\n",
    "\n",
    "response = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": content}]})\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "print(data['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## :question: Exercise 1 - German Translation\n",
    "\n",
    "* Exercise: Write a prompt that generates the expected completion\n",
    "* Input text: `I was enjoying the sun, but then a huge cloud came and covered the sky.`\n",
    "* Expected completion: `Ich genoss die Sonne, aber dann kam eine riesige Wolke und bedeckte den Himmel.`\n",
    "\n",
    "## :question: Exercise 2 - Classification\n",
    "\n",
    "* Exercise: Write a prompt that generates the expected completion\n",
    "* Input text: `Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing.`\n",
    "* Expected completion (or similar):\n",
    "  ``` \n",
    "  Positive: 0.75\n",
    "  Neutral: 0.20\n",
    "  Negative: 0.05\n",
    "  ```\n",
    "\n",
    "## :question: Exercise 3 - Multiple Tasks\n",
    "\n",
    "* Exercise: Write a prompt that generates the expected completion\n",
    "* Input text: `I was enjoying the sun, but then a huge cloud came and covered the sky.`\n",
    "* Expected completion:\n",
    "  ```\n",
    "  {\n",
    "  Â  Â  \"translated\": \"Ich genoss die Sonne, aber dann kam eine riesige Wolke und bedeckte den Himmel.\",\n",
    "  Â  Â  \"negated\": \"I was not enjoying the sun, and no huge cloud came and covered the sky.\",\n",
    "  Â  Â  \"third_person\": \"She was enjoying the sun, but then a huge cloud came and covered the sky.\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "## :question: Exercise 4 - Fashion product description\n",
    "\n",
    "* Exercise: Write a prompt that generates the expected completion\n",
    "* Input text:\n",
    "  ```\n",
    "  Season: Winter\n",
    "  Style: Sweater\n",
    "  Gender: Female\n",
    "  Target group: Teenager\n",
    "  Material: Cotton\n",
    "  ```\n",
    "* Expected completion (or similar):\n",
    "  ```\n",
    "  Stay warm and stylish this winter with our cozy cotton sweaters, perfect for the fashion-forward teenager. Refresh your wardrobe with the latest winter styles from our collection.\n",
    "  ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we used the Azure OpenAI API directly to query information about our instance of the Azure OpenAI service and to send a prompt to an OpenAI model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we will look at using the OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [OpenAI Packages/Libraries](../02-OpenAIPackages/openai.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
